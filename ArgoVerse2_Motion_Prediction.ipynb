{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependenceis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install omegaconf\n",
    "!pip install  pyntcloud\n",
    "!pip install open3d\n",
    "!pip install OpenCV\n",
    "!pip install Plotly\n",
    "!pip install psutil requests\n",
    "!apt install aria2\n",
    "!apt-get install -y orca\n",
    "import tarfile\n",
    "import os\n",
    "import pyarrow.feather as feather\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from ipywidgets import Button, VBox\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as pyplot\n",
    "import pyarrow.feather as feather\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create directories for train and test files if they don't exist\n",
    "!mkdir -p /argotrain\n",
    "#!mkdir -p /argotest\n",
    "\n",
    "# Train 1\n",
    "!aria2c -x 16 https://s3.amazonaws.com/argoverse/datasets/av2/tars/motion-forecasting/train.tar -d /argotrain -o train-000.tar\n",
    "\n",
    "# Test 1\n",
    "#!aria2c -x 16 https://s3.amazonaws.com/argoverse/datasets/av2/tars/sensor/test-000.tar -d /argotest -o test-000.tar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deccompressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with tarfile.open('/argotrain/train-000.tar', 'r') as tar:\n",
    "    tar.extractall('/argotrain')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "list_of_parquet_files = os.listdir(\"/argotrain/train\")\n",
    "#\"/argotrain/train/0000b0f9-99f9-4a1f-a231-5be9e4c523f7/scenario_0000b0f9-99f9-4a1f-a231-5be9e4c523f7.parquet\"\n",
    "list_of_parquet_files_string=[]\n",
    "for i in range(199908):\n",
    "  list_of_parquet_files_string.append(\"/argotrain/train/\"+list_of_parquet_files[i]+\"/scenario_\"+list_of_parquet_files[i]+\".parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "covered_time = 80      # Observed timesteps\n",
    "future_time = 30       # Future timesteps\n",
    "max_objects = 80       # Maximum number of objects per scenario, made through analysis on average count of objects per scneriar, mean was 55.5\n",
    "bins = 120              # Number of bins for discretization, made arbitrarly, no reason behind it\n",
    "batch_size = 16        # Batch size for training\n",
    "num_epochs = 100        # Number of training epochs\n",
    "learning_rate = 1e-4   # Learning rate for optimizer\n",
    "\n",
    "# Pre-determined Global Bin Ranges (Set based on our prior analysis, check the ReadMe for more info at https://github.com/hashemJaber/Motion-Predction-for-cars)\n",
    "x_range_min = 0.0\n",
    "x_range_max = 41.7139\n",
    "y_range_min = -5.5628\n",
    "y_range_max = 6.2710\n",
    "heading_range_min = -0.7035\n",
    "heading_range_max = 0.7346\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1. Extract World Trajectories\n",
    "def extract_world_trajectories(parquet_path:str, max_objects:int=80, observed_timesteps:int=80):\n",
    "    \"\"\"\n",
    "    Extract world trajectories for the observed timesteps.\n",
    "    Args:\n",
    "        parquet_path: str  (Path to the .parquet file)\n",
    "        max_objects: int (Maximum number of objects to extract)\n",
    "        observed_timesteps: int (The number of timesteps to include as input (i.e., the history up to t))\n",
    "    Returns:\n",
    "        World trajectory array of shape (max_objects, observed_timesteps, feature_dim).\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    df = df.sort_values(by=['track_id', 'timestep'])\n",
    "    features = ['position_x', 'position_y', 'heading', 'velocity_x', 'velocity_y', 'object_category']\n",
    "\n",
    "    grouped = df.groupby('track_id')\n",
    "    objects = [object_group[features].to_numpy()[:observed_timesteps]\n",
    "               for _, object_group in grouped if len(object_group) >= observed_timesteps]\n",
    "\n",
    "\n",
    "    # Pad or truncate to max_objects, maybe a bad opition subject to change\n",
    "    num_objects = min(len(objects), max_objects)\n",
    "    objects_array = np.zeros((max_objects, observed_timesteps, len(features)))\n",
    "    objects_array[:num_objects] = objects[:num_objects]\n",
    "    #print(\"objects_array: \",objects_array.shape)\n",
    "    #print(\"extract_world_trajectories: \",objects_array)\n",
    "\n",
    "    return objects_array\n",
    "\n",
    "\n",
    "\n",
    "# 2. Extract Focused Object Trajectory\n",
    "def extract_focused_object_trajectory(parquet_path:str, observed_timesteps:int=80):\n",
    "    \"\"\"\n",
    "    Extract the focused object's trajectory up to the observed timesteps.\n",
    "\n",
    "    NOTE: THIS MIGHT SEEM REDUNTANT FOR NOW, DUE TO THE WORLD TRAJECTORIES ALREADY INCLUDING THIS INFO\n",
    "    BUT THIS IS SUBJECT TO CHANGE ONCE WE RESOLVE THE HD MAP REPRESENATION\n",
    "\n",
    "    Args:\n",
    "        parquet_path: str (Path to the .parquet file)\n",
    "        observed_timesteps: int (The number of timesteps to include as input (i.e., the history up to t))\n",
    "\n",
    "    Returns:\n",
    "        Focused object trajectory array of shape (observed_timesteps, feature_dim).\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    focal_track_id = df['focal_track_id'].iloc[0]\n",
    "    focused_object_df = df[df['track_id'] == focal_track_id]\n",
    "\n",
    "    features = ['position_x', 'position_y', 'heading', 'velocity_x', 'velocity_y', 'object_category']\n",
    "    focused_object_df=focused_object_df[features].to_numpy()[:observed_timesteps]\n",
    "    #print(\"focused_object_df: \",focused_object_df.shape)\n",
    "\n",
    "    # Pad or truncate to max_objects\n",
    "    #num_objects = min(len(objects), max_objects)\n",
    "    #print(\"focused_object_df: \",focused_object_df.shape)\n",
    "    #print(\"focused_object_df: \",focused_object_df[:1])\n",
    "    return focused_object_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
